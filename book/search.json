[
  {
    "objectID": "openmp.html",
    "href": "openmp.html",
    "title": "3  Introdução à Programação Paralela com OpenMP",
    "section": "",
    "text": "3.1 Introdução\n– Paulo H. P. da Silva  phps6200@gmail.com\nNas últimas décadas, a evolução da computação deixou de se concentrar apenas no aumento da frequência dos processadores e passou a investir na multiplicação de núcleos de processamento. Hoje, mesmo computadores pessoais e notebooks comuns contam com múltiplos cores, e servidores e supercomputadores chegam a ter dezenas ou centenas de núcleos trabalhando em conjunto. Essa mudança de paradigma exige que os programas sejam capazes de executar tarefas em paralelo, aproveitando ao máximo os recursos de hardware disponíveis.\nO OpenMP (Open Multi-Processing) surge como uma solução prática e padronizada para explorar o paralelismo em sistemas de memória compartilhada. Trata-se de uma API amplamente utilizada, que permite adicionar paralelismo a programas escritos em C, C++ e Fortran de forma incremental, sem a necessidade de reescrever completamente o código. Seu modelo de programação é baseado no conceito fork–join, facilitando a adaptação de códigos sequenciais, permitindo ganhos de desempenho significativos com alterações relativamente pequenas.\nO aprendizado do OpenMP é progressivo, sendo possível começar paralelizando apenas um laço de repetição e, avançar para outras técnicas, como scheduling dinâmico, tarefas independentes (tasks) e vetorização (SIMD).",
    "crumbs": [
      "opemp-resumo.qmd",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introdução à Programação Paralela com OpenMP</span>"
    ]
  },
  {
    "objectID": "openmp.html#padrão-openmp-compiladores-bibliotecas-e-implementações",
    "href": "openmp.html#padrão-openmp-compiladores-bibliotecas-e-implementações",
    "title": "3  Introdução à Programação Paralela com OpenMP",
    "section": "3.2 Padrão OpenMP, compiladores, bibliotecas e Implementações",
    "text": "3.2 Padrão OpenMP, compiladores, bibliotecas e Implementações\nA abordagem do OpenMP é de mais alto nível, com uso de diretivas de compilação: instruções inseridas no código-fonte para indicar regiões paralelas. Funcionam como anotações que indicam seções paralelas do código sem a necessidade de reescrever toda a aplicação, permitindo testes e ajustes graduais. São implementadas usando-se as diretivas de pré-processamento #pragma, em C/C++, e sentinelas !$, no Fortran.\nO modelo de programação do OpenMP trabalha em sistemas de memória compartilhada e é baseado no conceito fork–join: o programa inicia com uma única thread (master), que cria múltiplas threads para executar regiões paralelas (fork) explicitamente ou implicitamente. e, ao final, sincroniza todas elas (join).\nO padrão OpenMP é suportado por praticamente todos os compiladores atuais: GCC (GNU Compiler Collection): suporte a OpenMP via -fopenmp; LLVM/Clang: suporte moderno com mais otimizações; Intel oneAPI / ICC: otimizações específicas para processadores Intel. IBM XL C/C++ e Fortran: suporte em sistemas de alto desempenho.\nA utilização da biblioteca de OpenMP com a flag -fopenmp para C/C++ permite o acesso às seguintes funções:\n\nint omp_get_thread_num(): retorna o identificador da thread.\nvoid omp_set_num_threads(int num_threads): indica o número de threads a executar na região paralela.\nint omp_get_num_threads(): retorna o número de threads que estão executando no momento.\n\nPara a execução dos exemplos posteriores (construidos em C), será utilizado o compilador GCC com a flag -fopenmp, para facilitar as execuções, um exemplo de arquivo makefile é disponibilizado, onde name é a variável que define o nome do arquivo .c:\nname=example\n\nall:\n    gcc -fopenmp ${name}.c -o ${name}.exe\n\nclean:\n    rm -rf *.o ${name}.exe",
    "crumbs": [
      "opemp-resumo.qmd",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introdução à Programação Paralela com OpenMP</span>"
    ]
  },
  {
    "objectID": "openmp.html#diretivas-de-compilação",
    "href": "openmp.html#diretivas-de-compilação",
    "title": "3  Introdução à Programação Paralela com OpenMP",
    "section": "3.3 Diretivas de Compilação",
    "text": "3.3 Diretivas de Compilação\nAs diretivas são instruções especiais que informam ao compilador como paralelizar o código. São formadas por construtores e cláusulas, os quais podem definir o escopo de variáveis, regras de concorrência e algoritmos de escalonamento utilizado. Cada construtor possui diferentes cláusulas.\nAs principais diretivas são:\n#pragma omp parallel: cria uma região paralela. Podendo conter cláusulas que definem o escopo de variáveis ou mesmo o número de threads para essa região.\nExemplo de utilização do construtor parallel com as funções da biblioteca omp, em uma região sem paralelismo, com paralelismo e paralilismo com número de threads definida:\n#include &lt;omp.h&gt;\n#include &lt;stdio.h&gt;\n\nint main()\n{\n  int i;\n  int omp_np;  /* Número de Processadores. */\n  int omp_nt;  /* Número de threads OpenMP. */\n  int omp_tid; /* Id da Thread OpenMP. */\n\n  /* Teste 1 (Sem utilização de paralelismo) */\n  printf(\"Teste 1 --------------------------------------------\\n\");\n  /* Traz os parâmetros do OpenMP utilizando as funções. */\n  omp_np = omp_get_num_procs();   /* Traz o número de processadores. */\n  omp_nt = omp_get_num_threads(); /* Traz o número de threads. */\n  omp_tid = omp_get_thread_num(); /* Traz o id da thread OpenMP. */\n  printf(\"Thread_id: %d #Processadores: %d #OpenMP Threads: %d\\n\", omp_tid, omp_np, omp_nt);\n\n  /* Teste 2 (Com utilização de paralelismo) */\n  printf(\"Teste 2 --------------------------------------------\\n\");\n#pragma omp parallel\n  {\n    omp_np = omp_get_num_procs();   /* Traz o número de processadores. */\n    omp_nt = omp_get_num_threads(); /* Traz o número de threads. */\n    omp_tid = omp_get_thread_num(); /* Traz o id da thread OpenMP.*/\n    printf(\"Thread_id: %d #Processadores: %d #OpenMP Threads: %d\\n\", omp_tid, omp_np, omp_nt);\n  }\n\n  /* Teste 3 (Com utilização de paralelismo e controle do número de threads) */\n  printf(\"Teste 3 --------------------------------------------\\n\");\n#pragma omp parallel num_threads(8)\n  {\n    omp_np = omp_get_num_procs();   /* Traz o número de processadores. */\n    omp_nt = omp_get_num_threads(); /* Traz o número de threads. */\n    omp_tid = omp_get_thread_num(); /* Traz o id da thread OpenMP. */\n    printf(\"Thread_id: %d #Processadores: %d #OpenMP Threads: %d\\n\", omp_tid, omp_np, omp_nt);\n  }\n  return 0;\n}\n#pragma omp for: distribui iterações de um laço entre threads. Ao adentrar uma região paralela, o construtor for é utilizado para distribuir o trabalho entre as threads. Pode ser utilizado em combinação com o construtor parallel.\nExemplo de código com utilização do construtor for:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main()\n{\n  int id, i;\n\n  printf(\"Thread_id: %d: Antes da regiao paralela\\n\", omp_get_thread_num());\n\n#pragma omp parallel num_threads(4)\n  {\n    // Todas as threads executam o código a partir deste ponto.\n    // Obter ID da thread\n    id = omp_get_thread_num();\n\n#pragma omp for\n    for (i = 0; i &lt; 16; i++)\n    {\n      printf(\"Thread_id: %d: Trabalhando na iteracao %d do loop...\\n\", id, i);\n    }\n  }\n\n  printf(\"Thread_id: %d: Depois da região paralela...\\n\", omp_get_thread_num());\n\n  return 0;\n}\nExemplo de código com parallel e for combinados:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main()\n{\n  int id, i;\n\n  printf(\"Thread_id: %d: Antes da regiao paralela\\n\", omp_get_thread_num());\n\n#pragma omp parallel for num_threads(4)\n  for (i = 0; i &lt; 16; i++)\n  {\n    printf(\"Thread_id: %d: Trabalhando na iteracao %d do loop...\\n\", omp_get_thread_num(), i);\n  }\n\n  printf(\"Thread_id: %d: Depois da regiao paralela...\\n\", omp_get_thread_num());\n\n  return 0;\n}\nAlém disso, o construtor for pode ter seu algoritmo de escalonamento especificado pela cláusula schedule. Os dois algoritimos principais são o static, dividindo igualmente a carga de trabalho entre todas as threads e o dynamic, que define um chunk, uma quantidade de iterações para as threads executarem, diferente da static, quando uma thread termina de executar uma chunk, ele pode requisitar outra, portanto não necessariamente todas as threads realizaram o mesmo trabalho. O valor padrão do algoritimo é o static.\nExemplo utilizando o algoritimo dynamic:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main()\n{\n  int id, i;\n\n  printf(\"Thread_id: %d: Antes da regiao paralela\\n\", omp_get_thread_num());\n\n#pragma omp parallel for num_threads(4) schedule(dynamic, 2)\n  for (i = 0; i &lt; 16; i++)\n  {\n    printf(\"Thread_id: %d: Trabalhando na iteracao %d do loop...\\n\", omp_get_thread_num(), i);\n  }\n\n  printf(\"Thread_id: %d: Depois da regiao paralela...\\n\", omp_get_thread_num());\n\n  return 0;\n}\n#pragma omp sections: divide o trabalho em blocos independentes, ou seja, trabalhos não iterativos.\nExemplo de código com o construtor sections:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main(int argc, char *argv[])\n{\n\n  int id;\n\n  fprintf(stdout, \"Thread_id: %d: Antes da Regio Paralela.\\n\", omp_get_thread_num());\n\n#pragma omp parallel num_threads(3)\n  {\n    id = omp_get_thread_num();\n#pragma omp sections\n    {\n#pragma omp section\n      fprintf(stdout, \"Thread_id: %d - Executando o bloco de codigo 1.\\n\", id);\n\n#pragma omp section\n      fprintf(stdout, \"Thread_id: %d - Executando o bloco de codigo 2.\\n\", id);\n\n#pragma omp section\n      fprintf(stdout, \"Thread_id: %d - Executando o bloco de codigo 3.\\n\", id);\n    }\n  }\n\n  fprintf(stdout, \"Thread_id: %d - Depois da Regio Paralela.\\n\", omp_get_thread_num());\n\n  return 0;\n}\nO construtor sections possui uma cláusula chamada reduction, que é utilizada para indicar uma operação a ser realizada sob todas as cópias de uma variável definida dentro do código de cada thread, o exemplo a seguir indica a redução da variável sum, que deve ser somada ao fim da execução das threads:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main()\n{\n  int i, id;\n  int sum = 0;\n\n  fprintf(stdout, \"Thread_id: %d Antes da Regiao Paralela.\\n\", omp_get_thread_num());\n\n#pragma omp parallel num_threads(2)\n  {\n    id = omp_get_thread_num();\n#pragma omp sections reduction(+ : sum)\n    {\n#pragma omp section\n      {\n        fprintf(stdout, \"   Thread_id: %d - Executando o bloco de codigo 1.\\n\", id);\n        for (i = 0; i &lt; 2048; i++)\n        {\n          sum += i;\n        }\n      }\n\n#pragma omp section\n      {\n        fprintf(stdout, \"   Thread_id: %d - Executando o bloco de codigo 2.\\n\", id);\n        for (i = 0; i &lt; 2048; i++)\n        {\n          sum += i;\n        }\n      }\n    }\n  }\n\n  fprintf(stdout, \"Thread_id: %d Depois da Regiao Paralela.\\n\", omp_get_thread_num());\n  fprintf(stdout, \"Thread_id: %d sum: %d\\n\", omp_get_thread_num(), sum);\n\n  return 0;\n}\n#pragma omp task, #pragma omp taskwait e #pragma omp single: O construtor task cria tarefas explícitas para as threads executarem, possui semelhanças com o construtor sections, contudo o sections é uma divisão estática de blocos, dependente da finalização da section em si para continuar. Uma task possui uma execução dinâmica, sendo o número de tarefas definido no tempo de execução, sendo mais flexível. O construtor taskwait age como uma barreira de espera para as threads que criaram as tasks, fazendo com que elas esperem a execução das tasks antes de continuar as suas próprias execuções. O construtor single pode ser utilizado para criar apenas uma tarefa, caso não seja utilizado, todas as threads da região paralela irão criar uma nova task, o que pode não ser o comportamento desejado.\nExemplo de código utilizando os construtores task e single:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nint main()\n{\n  int id;\n  int x = 50;\n\n  fprintf(stdout, \"Thread_id: %d Antes da Regiao Paralela.\\n\", omp_get_thread_num());\n\n#pragma omp parallel num_threads(4) firstprivate(x) private(id)\n  {\n    id = omp_get_thread_num();\n    fprintf(stdout, \"  Thread_id: %d, Todas as threads executam.\\n\", id);\n\n#pragma omp single\n    {\n      fprintf(stdout, \"  Thread_id: %d, Antes de criar tasks.\\n\", id);\n#pragma omp task if (x &gt; 10)\n      {\n        fprintf(stdout, \"    Thread_id: %d, Trabalhando na task 1.\\n\", omp_get_thread_num());\n      }\n\n#pragma omp task if (x &gt; 20)\n      {\n        fprintf(stdout, \"    Thread_id: %d, Trabalhando na task 2.\\n\", omp_get_thread_num());\n      }\n\n      fprintf(stdout, \"    Thread_id: %d, Antes do taskwait.\\n\", id);\n#pragma omp taskwait\n      fprintf(stdout, \"    Thread_id: %d, Depois do taskwait.\\n\", id);\n\n#pragma omp task\n      {\n        fprintf(stdout, \"    Thread_id: %d, Trabalhando na task 3.\\n\", omp_get_thread_num());\n      }\n    }\n  }\n\n  fprintf(stdout, \"Thread_id: %d, Depois da Regiao Paralela.\\n\", omp_get_thread_num());\n\n  return 0;\n}\n#pragma omp taskloop: Permite distribuir as iterações de um ou mais laços aninhados para tarefas, sendo escalonadas para serem executadas. Com esse construtor é possível determinar o número de threads que serão criadas para a execução do laço com a cláusula num_tasks() e determinar o tamanho do subconjunto de iterações que cada thread irá executar através da cláusula grainsize().\nExemplo de código com o construtor taskloop:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\nvoid function()\n{\n  int i, j;\n  fprintf(stdout, \"Thread_id: %d - taskloop...\\n\", omp_get_thread_num());\n#pragma omp taskloop num_tasks(8) grainsize(2)\n  for (i = 0; i &lt; 16; i++)\n  {\n    for (j = 0; j &lt; i; j++)\n    {\n      fprintf(stdout, \"Thread_id: %d - Trabalhando na iteracao (%d,%d).\\n\", omp_get_thread_num(), i, j);\n    }\n  }\n}\n\nint main()\n{\n\n  fprintf(stdout, \"Thread_id: %d - Antes da Regiao Paralela.\\n\", omp_get_thread_num());\n\n#pragma omp parallel num_threads(4)\n  {\n#pragma omp single\n    {\n      fprintf(stdout, \"  Thread_id: %d - Antes das tasks.\\n\", omp_get_thread_num());\n#pragma omp taskgroup\n      {\n#pragma omp task\n        {\n          fprintf(stdout, \"Thread_id: %d - Trabalhando em uma outra task independente.\\n\", omp_get_thread_num());\n        }\n\n#pragma omp task\n        {\n          fprintf(stdout, \"Thread_id: %d - Trabalhando na task function().\\n\", omp_get_thread_num());\n          function();\n        }\n      }\n    }\n  }\n\n  fprintf(stdout, \"Thread_id: %d - Depois da Regiao Paralela.\\n\", omp_get_thread_num());\n\n  return 0;\n}\n#pragma omp simd: pode ser aplicado a um laço diretamente indicando que múltiplas iterações do laço podem ser executadas concorrentemente usando instruções SIMD (Single Instruction Multiple Data), como em multiplicação de vetores, onde a mesma instrução é aplicada em todas as posições dos vetores. Podendo ser combinado com os construtores for e taskloop.\nExemplo de código com construtor simd:\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;omp.h&gt;\n\n// Tamanho dos vetores.\n#define N 1048576\n\n// Entrada e saída.\ndouble v_a[N];\ndouble v_b[N];\ndouble v_s[N];\n\nvoid init_array()\n{\n  fprintf(stdout, \"Inicializando os arrays.\\n\");\n  int i;\n  // Initialize vectors on host.\n  for (i = 0; i &lt; N; i++)\n  {\n    v_a[i] = 0.5;\n    v_b[i] = 0.5;\n  }\n}\n\nint main(int argc, char **argv)\n{\n  int i;\n  double res;\n\n  /* Inicialização  dos vetores. */\n  init_array();\n\n  fprintf(stdout, \"Thread_id: %d - Antes do simd.\\n\", (long int)omp_get_thread_num());\n#pragma omp simd\n  for (i = 0; i &lt; N; i++)\n  {\n    res += v_a[i] * v_b[i];\n    v_s[i] += v_a[i] * v_b[i];\n  }\n\n  fprintf(stdout, \"Thread_id: %d - Depois do simd.\\n\", (long int)omp_get_thread_num());\n\n  fprintf(stdout, \"Thread_id: %d - resultado: %g\\n\", (long int)omp_get_thread_num(), res);\n\n  return 0;\n}",
    "crumbs": [
      "opemp-resumo.qmd",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introdução à Programação Paralela com OpenMP</span>"
    ]
  },
  {
    "objectID": "openmp.html#sec-openmp-consid-finais",
    "href": "openmp.html#sec-openmp-consid-finais",
    "title": "3  Introdução à Programação Paralela com OpenMP",
    "section": "3.4 Considerações Finais",
    "text": "3.4 Considerações Finais\nO OpenMP permite identificar oportunidades de paralelismo, dividir o trabalho de forma equilibrada, sincronizar apenas quando necessário e medir continuamente o impacto das mudanças dentro do código. Sendo flexível e portátil, ele permite que você comece paralelizando um único laço e avançando para arquiteturas mais complexas, ajustando scheduling, explorando tarefas independentes e combinando paralelismo com outras técnicas de otimização.\nO próximo passo é continuar testando diferentes configurações, medindo resultados, identificando gargalos e refinando o código. A prática constante e a análise crítica são as chaves para dominar o OpenMP e, mais amplamente, a programação paralela.",
    "crumbs": [
      "opemp-resumo.qmd",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introdução à Programação Paralela com OpenMP</span>"
    ]
  },
  {
    "objectID": "openmp.html#referências",
    "href": "openmp.html#referências",
    "title": "3  Introdução à Programação Paralela com OpenMP",
    "section": "3.5 Referências",
    "text": "3.5 Referências\n1.OpenMP Architecture Review Board. OpenMP Application Programming Interface. Disponível em: https://www.openmp.org.\n2.Capítulo 3: Introdução à Programação Paralela com OpenMP: Além das Diretivas de Compilação. Disponível em: https://www.researchgate.net/publication/320775430_Capitulo_3_Introducao_a_Programacao_Paralela_com_OpenMP_Alem_das_Diretivas_de_Compilacao.",
    "crumbs": [
      "opemp-resumo.qmd",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introdução à Programação Paralela com OpenMP</span>"
    ]
  }
]