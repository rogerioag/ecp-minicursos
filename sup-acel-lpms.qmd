# Suporte a Aceleradores em Linguagens de Programação em Sistemas Heterogêneos

-- Christopher Eduardo Zai<br>
<christopher.310704@alunos.utfpr.edu.br>

> __Resumo:__
> Este minicurso aborda o suporte a aceleradores (GPUs/FPGAs) em linguagens de programação, fundamental para a computação paralela de alto desempenho (HPC). O foco reside em **quatro pilares arquiteturais**. **C++** será explorado por sua portabilidade de desempenho usando padrões abertos como SYCL e abstrações avançadas. **Fortran**, o pilar da computação científica, ilustrará a eficácia dos modelos de aceleração baseados em diretivas (OpenACC/OpenMP). **Python** demonstrará como a produtividade é alcançada via compilação JIT (Numba) e delegação a *backends* nativos. Por fim, **Julia** apresentará sua integração nativa de baixo atrito através do sistema de *multiple dispatch* e *arrays* de GPU (CuArray). O objetivo é dominar os mecanismos de *offloading* e gestão de memória para otimizar aplicações intensivas.

## Introdução {#sec-sup-acel-lpms-intro}
O panorama da computação de alto desempenho (HPC) e da inteligência artificial (IA) sofreu uma transformação fundamental nas últimas décadas. Historicamente, o aumento constante na frequência de clock dos processadores, conhecido por impulsionar a Lei de Moore, garantia que o software ficasse intrinsecamente mais rápido a cada nova geração de hardware. Contudo, essa era chegou ao fim com o limite físico e térmico dos processadores de propósito geral (CPUs).  

Essa estagnação impulsionou um novo paradigma: a computação heterogênea. O crescimento do desempenho passou a depender não mais da velocidade de um único núcleo, mas sim da exploração do paralelismo massivo oferecido por processadores especializados, conhecidos como aceleradores. Dispositivos como Unidades de Processamento Gráfico (GPUs), FPGAs e TPUs, projetados para executar milhares de operações simultaneamente, tornaram-se o novo requisito padrão para cargas de trabalho intensivas, como o treinamento de modelos de Machine Learning e simulações científicas complexas.  

O desafio crucial reside em como linguagens de programação de alto nível, valorizadas por sua alta produtividade e facilidade de uso (como Python, Julia e C++), conseguem coordenar e descarregar (*offload*) a execução de tarefas para esses aceleradores, mantendo o desempenho próximo ao código nativo. Este minicurso visa dissecar os mecanismos arquiteturais e as bibliotecas que permitem essa integração eficiente, focando nas abordagens distintas dos nossos pilares para dominar a programação em ambientes de hardware heterogêneo.

Para navegar neste novo paradigma, é essencial que o participante compreenda tanto o hardware especializado quanto as estratégias de software. Assim, este minicurso iniciará com uma revisão das linguagens foco (C++, Fortran, Python e Julia) e a taxonomia dos aceleradores. Em seguida, mergulharemos nos modelos de programação e nas bibliotecas específicas que permitem o *offloading* e a gestão otimizada de memória, garantindo que você possa aplicar esses conhecimentos para obter ganhos de desempenho significativos em aplicações intensivas em computação.

## Linguagens de Programação em Sistemas Heterogêneos
Para começarmos vamos conhecer as nossas ferramentas e suas filosofias de aceleração. Este capítulo se dedica a isso, apresentando um básico de C++, Fortran, Python e Julia. Por hora, explicaremos como funciona cada linguagem e um exemplo sequencial de código sem nenhuma otimização envolvendo suporte a aceleradores.

### C++
Embora o C++ tenha sido formalizado em 1985, sua relevância e aplicação permanecem inigualáveis no domínio da Computação de Alto Desempenho (HPC). Longe de ser uma linguagem estagnada, o C++ se aprimora continuamente, incorporando recursos avançados de programação genérica, gerenciamento de recursos e modularidade nos padrões ISO recentes. Devido à sua estabilidade, controle de baixo nível sobre a memória e a máquina, e um ecossistema robusto e bem testado, a maioria dos projetos críticos de desempenho é desenvolvida em C++.

O C++ fornece a base para códigos extremamente eficientes. A constante atualização da linguagem, com recursos como políticas de execução paralela (`std::par`) introduzidas no C++17, garante que ela permaneça a fundação das bibliotecas mais avançadas de abstração de aceleradores.

Abaixo, apresentamos um pequeno exemplo de multiplicação de matrizes, uma operação fundamental e intensiva que serve como um excelente candidato para aceleração:

```cpp
#include <iostream>
#include <vector>
#include <chrono>

using namespace std;

// Tamanhos das matrizes: Multiplicar A(N x M) por B(M x P)
const int N = 256; 
const int M = 256; 
const int P = 256; 

void initialize_matrix(vector<int>& matrix, int size, int value_start) {
    for (int i = 0; i < size; ++i) {
        matrix[i] = value_start + i;
    }
}

int main() {
    // Aloca e inicializa as matrizes na memória da CPU (Host)
    vector<int> A(N * M);
    vector<int> B(M * P);
    vector<int> C(N * P, 0); // Matriz Resultado (inicializada com zeros)

    initialize_matrix(A, N * M, 1);
    initialize_matrix(B, M * P, 2);

    // Multiplicação de Matrizes Sequencial (C = A * B)
    // O(N*M*P) complexidade - um núcleo de computação intensivo
    for (int i = 0; i < N; ++i) {
        for (int j = 0; j < P; ++j) {
            int sum = 0;
            for (int k = 0; k < M; ++k) {
                sum += A[i * M + k] * B[k * P + j];
            }
            C[i * P + j] = sum;
        }
    }

    // Imprime um elemento para verificação
    cout << "C[0, 0] = " << C[0] << endl; 
    
    // O último elemento requer o cálculo do índice
    cout << "C[N-1, P-1] = " << C[(N - 1) * P + (P - 1)] << endl;

    return 0;
}
```

O desafio será transformar este núcleo de computação (compute kernel) para ser executado de forma massivamente paralela no acelerador, utilizando as abstrações que veremos adiante.

### Python

Python, criada no início dos anos 90, é uma linguagem de programação de alto nível, interpretada, e universalmente reconhecida por sua sintaxe limpa e legibilidade. Sua filosofia de design enfatiza a produtividade do desenvolvedor, permitindo que conceitos complexos sejam expressos em menos linhas de código do que em linguagens como C++.

Embora a natureza interpretada do Python (conhecida como CPython) resulte em um desempenho inferior para tarefas numericamente intensivas, seu verdadeiro poder reside em seu vasto ecossistema de bibliotecas. Ferramentas como NumPy, SciPy e Pandas, implementadas em C e Fortran, delegam as operações pesadas a *backends* nativos e altamente otimizados. Essa arquitetura permite que o Python atue como uma "linguagem de cola" de alta produtividade, orquestrando tarefas de alto desempenho sem sacrificar a simplicidade.

Abaixo, apresentamos um exemplo que gera o conjunto de Mandelbrot, um fractal cuja computação é inerentemente paralelizável, pois o cálculo de cada pixel é independente dos outros.

```python
import numpy as np
from PIL import Image
from time import perf_counter

def mandelbrot_kernel(c, max_iter):
    """
    Verifica se um número complexo 'c' pertence ao conjunto de Mandelbrot.
    Retorna o número de iterações até 'escapar'.
    """
    z = 0
    n = 0
    while abs(z) <= 2 and n < max_iter:
        z = z*z + c
        n += 1
    return n

def create_fractal(min_x, max_x, min_y, max_y, width, height, max_iter):
    """
    Cria a imagem do fractal de Mandelbrot iterando sobre cada pixel.
    """
    img = np.zeros((height, width), dtype=np.uint8)
    pixel_size_x = (max_x - min_x) / width
    pixel_size_y = (max_y - min_y) / height

    for x in range(width):
        for y in range(height):
            real = min_x + x * pixel_size_x
            imag = min_y + y * pixel_size_y
            color = mandelbrot_kernel(complex(real, imag), max_iter)
            img[y, x] = color

    return img

fractal_image = create_fractal(-2.0, 1.0, -1.0, 1.0, 1024, 768, 255)
Image.fromarray(fractal_image).save('mandelbrot_sequential.png')
```

Este código, executado de forma puramente sequencial, servirá como nossa base de comparação. O desafio, assim como no C++, será utilizar as ferramentas do ecossistema Python para descarregar a execução dos laços computacionalmente intensivos para um acelerador.

### Julia

(A ser desenvolvido...)

### Fortran: O Pilar Adaptável da Computação Científica

Para uma analise verdadeiramente completa, é necessário incluir o Fortran (**For**mula **Tran**slation). Embora seja a linguagem de programação de alto nível mais antiga em uso contínuo, datando de 1957, sua inclusão aqui não é um equívoco. Sua eficiência inigualável para o processamento numérico de vetores e matrizes garante sua posição como a linguagem de fundação do HPC.

Se considerarmos "moderno" como a capacidade de uma linguagem de se adaptar e absorver as arquiteturas mais recentes, o Fortran é notavelmente moderno. Sua relevância nos sistemas heterogêneos reside na sua capacidade de suportar aceleradores através de modelos de programação baseados em diretivas—padrões abertos como OpenACC e OpenMP Offloading. Esses modelos permitem que o programador insira comentários especiais no código (pragmas) que instruem o compilador a descarregar automaticamente tarefas paralelas para a GPU, simplificando o gerenciamento de dados e o lançamento de kernels sem que o programador precise escrever código explícito de kernel.

## Estudos de Caso em Ecossistemas Alternativos

### Node.JS e WebGPU: Aceleração Pela Porta de Serviço

A busca por performance na computação heterogênea é tão onipresente que até mesmo ecossistemas tradicionalmente alheios ao HPC, como o JavaScript, estão se adaptando. O WebGPU é a nova API gráfica e de computação que se consolida como sucessora do WebGL. Sua relevância reside na sua capacidade de fornecer acesso moderno e unificado à GPU (baseado em Vulkan/Metal/DirectX 12).

Embora o JavaScript (front-end e back-end via Node.JS) não seja uma linguagem projetada para HPC, a existência de bindings e implementações como o Dawn (do Google) permite que o Node.JS utilize a WebGPU para rodar compute shaders de propósito geral no lado do servidor. Este é um exemplo fascinante de como a necessidade de aceleração em Machine Learning e tarefas intensivas está "contaminando" todas as plataformas, mesmo que o modelo de programação seja inerentemente mais complexo do que as soluções nativas.

### Taxonomia de Aceleradores

A computação heterogênea baseia-se no uso de aceleradores, dispositivos projetados para executar tarefas específicas com maior eficiência energética e maior taxa de transferência (throughput) do que CPUs equivalentes.

## Suporte a Aceleradores em Linguagens Modernas

## Bibliotecas e Implementações

## Modelo de Programação e Execução
...

## Considerações Finais {#sec-sup-acel-lpms-consid-finais}

## Referências

::: {#refs}
https://tecnoblog.net/responde/o-que-diz-a-lei-de-moore/ 
https://kfcdicasdigital.com/glossario/o-que-e-heterogeneous-computing/
https://gemini.google.com/share/26fec8ec6845 
https://pt.wikipedia.org/wiki/C%2B%2B 
https://pt.wikipedia.org/wiki/Python
https://pt.wikipedia.org/wiki/Julia_(linguagem_de_programa%C3%A7%C3%A3o)
:::